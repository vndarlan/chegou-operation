import streamlit as st
import requests
import re
import json
import time
import sqlite3
import os
from urllib.parse import urlparse, parse_qs
from bs4 import BeautifulSoup
from db_connection import get_db_connection


# Importa√ß√£o condicional para n√£o quebrar se n√£o estiver instalado
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

# ---------------------------------------------------------------------------- #
# CONFIGURA√á√ïES GERAIS DA APLICA√á√ÉO
# ---------------------------------------------------------------------------- #

# Inicializa√ß√£o da sess√£o
if "url_limpa" not in st.session_state:
    st.session_state.url_limpa = None

if "url_para_comprar" not in st.session_state:
    st.session_state.url_para_comprar = None

if "urls_para_comprar_lote" not in st.session_state:
    st.session_state.urls_para_comprar_lote = []

# ---------------------------------------------------------------------------- #
# FUN√á√ïES COMUNS
# ---------------------------------------------------------------------------- #

def get_engajamentos():
    """Obt√©m os engajamentos do banco de dados."""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # Create table if it doesn't exist
        if os.environ.get('RAILWAY_ENVIRONMENT'):
            # PostgreSQL
            c.execute("""
            CREATE TABLE IF NOT EXISTS engajamentos (
                id SERIAL PRIMARY KEY,
                nome TEXT,
                engajamento_id TEXT,
                funcionando TEXT,
                tipo TEXT DEFAULT 'Like'
            )
            """)
            
            # Check if sample data needs to be added (check if table is empty)
            c.execute("SELECT COUNT(*) FROM engajamentos")
            count = c.fetchone()[0]
            
            if count == 0:
                # Add sample data
                exemplos = [
                    ("Like Facebook", "101", "Sim", "Like"),
                    ("Amei Facebook", "102", "Sim", "Amei"),
                    ("Uau Facebook", "103", "Sim", "Uau")
                ]
                for exemplo in exemplos:
                    c.execute("""
                    INSERT INTO engajamentos (nome, engajamento_id, funcionando, tipo)
                    VALUES (%s, %s, %s, %s)
                    """, exemplo)
                
            # Check columns
            c.execute("SELECT column_name FROM information_schema.columns WHERE table_name='engajamentos'")
            columns = [col[0] for col in c.fetchall()]
            if "tipo" not in columns:
                c.execute("ALTER TABLE engajamentos ADD COLUMN tipo TEXT DEFAULT 'Like'")
        else:
            # SQLite (original code)
            if not os.path.exists("engajamentos.db"):
                c.execute('''CREATE TABLE IF NOT EXISTS engajamentos
                            (id INTEGER PRIMARY KEY, nome TEXT, engajamento_id TEXT, funcionando TEXT, tipo TEXT)''')
                # Inserir dados de exemplo
                exemplos = [
                    (1, "Like Facebook", "101", "Sim", "Like"),
                    (2, "Amei Facebook", "102", "Sim", "Amei"),
                    (3, "Uau Facebook", "103", "Sim", "Uau")
                ]
                c.executemany("INSERT OR IGNORE INTO engajamentos VALUES (?, ?, ?, ?, ?)", exemplos)
            
            # Check columns
            c.execute("PRAGMA table_info(engajamentos)")
            columns = [col[1] for col in c.fetchall()]
            if "tipo" not in columns:
                c.execute("ALTER TABLE engajamentos ADD COLUMN tipo TEXT DEFAULT 'Like'")
        
        conn.commit()
        
        # Get engagements
        c.execute("SELECT id, nome, engajamento_id, funcionando, tipo FROM engajamentos")
        rows = c.fetchall()
        conn.close()
        return rows
    except Exception as e:
        st.error(f"Erro ao acessar o banco de dados: {str(e)}")
        return []

# ---------------------------------------------------------------------------- #
# LAYOUT DA APLICA√á√ÉO CENTRALIZADO USANDO RECURSOS NATIVOS DO STREAMLIT
# ---------------------------------------------------------------------------- #

# N√£o usar st.set_page_config aqui pois causa erro em aplica√ß√µes multipage
# Vamos usar CSS para maximizar a largura dispon√≠vel

# Aplicar CSS para usar a largura total dispon√≠vel
st.markdown("""
<style>
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 95%;
    }
    .column-title {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 15px;
        text-align: center;
    }
    .stTextInput > div > div > input {
        width: 100%;
    }
    .stTextArea > div > div > textarea {
        width: 100%;
    }
    .stButton > button {
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# Criar um container de largura total
container = st.container()

# Criar as duas colunas principais com propor√ß√£o melhorada
with container:
    col_limpar, col_comprar = st.columns([5, 5])

# ---------------------------------------------------------------------------- #
#                      PARTE 1: LIMPAR URLs
# ---------------------------------------------------------------------------- #

with col_limpar:
    st.markdown("<div class='column-title'><h3>üßπ Limpar URLs de An√∫ncios</h3></div>", unsafe_allow_html=True)
    
    def check_selenium_available():
        """Checks if Selenium can be properly initialized in the current environment"""
        try:
            if not SELENIUM_AVAILABLE:
                return False
                
            # Try to initialize a headless browser to see if it works
            options = Options()
            options.add_argument('--headless')
            options.add_argument('--disable-gpu')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
        
            # Check if we're on Railway
            if os.environ.get('RAILWAY_ENVIRONMENT'):
                # Use the Chrome path in Docker
                chrome_path = "/usr/bin/google-chrome-stable"
                options.binary_location = chrome_path
            
                try:
                    # On Railway, create Chrome directly
                    browser = webdriver.Chrome(options=options)
                except Exception as e:
                    print(f"Erro inicializando Chrome no Railway: {str(e)}")
                    return False
            else:
                # Locally, use ChromeDriverManager
                try:
                    service = Service(ChromeDriverManager().install())
                    browser = webdriver.Chrome(service=service, options=options)
                except Exception as e:
                    print(f"Erro inicializando Chrome localmente: {str(e)}")
                    return False
                
            browser.quit()
            return True
        except Exception as e:
            print(f"Erro no check_selenium_available: {str(e)}")
            return False

    def extrair_url_real_via_browser(url):
        """
        Usa um navegador headless para abrir a URL do an√∫ncio e extrair a URL real.
        Esta fun√ß√£o simula o processo de clicar em "Copiar link" no an√∫ncio.
        """
        if not SELENIUM_AVAILABLE:
            return None
    
        # Configurar o navegador headless
        try:
            options = Options()
            options.add_argument('--headless')
            options.add_argument('--disable-gpu')
            options.add_argument('--no-sandbox')  # Necess√°rio para Docker
            options.add_argument('--disable-dev-shm-usage')  # Necess√°rio para Docker
            options.add_argument('--disable-notifications')
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-infobars')
        
            # Adicionar um User-Agent comum para evitar bloqueios
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36')
        
            # Check if we're on Railway
            if os.environ.get('RAILWAY_ENVIRONMENT'):
                # Use the Chrome path in Docker
                chrome_path = "/usr/bin/google-chrome-stable"
                options.binary_location = chrome_path
            
                # On Railway, create Chrome directly
                browser = webdriver.Chrome(options=options)
            else:
                # Locally, use ChromeDriverManager
                service = Service(ChromeDriverManager().install())
                browser = webdriver.Chrome(service=service, options=options)
        
            # Definir um tempo de espera razo√°vel
            wait_time = 8
            
            # Abrir a URL
            browser.get(url)
        
            # Aguardar o carregamento da p√°gina
            time.sleep(wait_time)
        
            # PRIORIDADE 1: Procurar diretamente por links de v√≠deo na p√°gina
            video_links = browser.find_elements(By.XPATH, '//a[contains(@href, "/videos/")]')
            for link in video_links:
                href = link.get_attribute('href')
                if href and '/videos/' in href:
                    # Verificar se √© um v√≠deo do Facebook (n√£o um link externo)
                    if 'facebook.com' in href:
                        browser.quit()
                        return href
        
            # PRIORIDADE 2: Verificar se h√° bot√£o "Ver Mais" ou similar e clicar
            try:
                ver_mais_buttons = browser.find_elements(By.XPATH, 
                    '//div[contains(text(), "Ver Mais") or contains(text(), "Saiba mais") or contains(text(), "See More")]')
                if ver_mais_buttons:
                    for button in ver_mais_buttons:
                        try:
                            button.click()
                            time.sleep(2)  # Esperar a p√°gina atualizar
                        
                            # Verificar novamente por links de v√≠deo ap√≥s clicar
                            video_links = browser.find_elements(By.XPATH, '//a[contains(@href, "/videos/")]')
                            for link in video_links:
                                href = link.get_attribute('href')
                                if href and '/videos/' in href and 'facebook.com' in href:
                                    browser.quit()
                                    return href
                        except:
                            pass  # Continuar tentando outros bot√µes se este falhar
            except Exception as e:
                pass
        
            # PRIORIDADE 5: Verificar se a URL da p√°gina mudou ap√≥s carregamento
            current_url = browser.current_url
            if current_url != url and "dco_ad_token" not in current_url:
                # Verificar se a URL atual parece ser um permalink ou um link de conte√∫do
                if any(x in current_url for x in ['/videos/', '/watch/', '/photo/']):
                    browser.quit()
                    return current_url
                
            # PRIORIDADE 6: Extrair todos os links do Facebook e tentar identificar o mais relevante
            all_links = browser.find_elements(By.TAG_NAME, 'a')
            fb_links = []
            video_links = []
        
            for link in all_links:
                href = link.get_attribute('href')
                if href and 'facebook.com' in href:
                    # Priorizar links que parecem ser v√≠deos
                    if '/videos/' in href:
                        video_links.append(href)
                    # Ou outros tipos de conte√∫do
                    elif any(x in href for x in ['/watch/', '/photo/', '/permalink/']):
                        fb_links.append(href)
        
            # Priorizar links de v√≠deo
            if video_links:
                browser.quit()
                return video_links[0]
            
            # Ou outro conte√∫do relevante
            if fb_links:
                browser.quit()
                return fb_links[0]
            
        except Exception as e:
            print(f"Erro Selenium: {str(e)}")
        finally:
            try:
                browser.quit()
            except:
                pass
    
        return None

    def extrair_via_api_mobile(url):
        """
        Tenta extrair a URL real utilizando a vers√£o m√≥vel da API do Facebook.
        Esta √© uma abordagem alternativa que pode funcionar em alguns casos.
        """
        try:
            # Converter para vers√£o m√≥vel (m.facebook.com)
            mobile_url = url.replace('www.facebook.com', 'm.facebook.com')
            
            # Adicionar headers para simular um navegador m√≥vel
            headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3',
            }
            
            response = requests.get(mobile_url, headers=headers, timeout=10)
            
            if response.status_code != 200:
                return None
            
            # Usar BeautifulSoup para analisar o HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # PRIORIDADE 1: Procurar links de v√≠deo expl√≠citos
            # Primeiro procurar links espec√≠ficos de v√≠deo (alta prioridade)
            video_patterns = [
                'a[href*="/videos/"]',  # Links de v√≠deo padr√£o
                'a[href*="/watch/"]',   # Links de assistir v√≠deo
                'video source[src]',    # Tags de v√≠deo direto
                'div[data-store*="videoID"]'  # Divs com ID de v√≠deo
            ]
            
            for pattern in video_patterns:
                elements = soup.select(pattern)
                if elements:
                    for element in elements:
                        if element.name == 'a' and element.get('href'):
                            href = element['href']
                            if not href.startswith('http'):
                                href = 'https://www.facebook.com' + href
                            return href
                        elif element.name == 'source' and element.get('src'):
                            src = element['src']
                            return src
                        elif element.name == 'div' and element.get('data-store'):
                            try:
                                data_store = json.loads(element['data-store'])
                                if 'videoID' in data_store:
                                    video_id = data_store['videoID']
                                    video_url = f"https://www.facebook.com/watch/?v={video_id}"
                                    return video_url
                            except:
                                pass
                
        except Exception as e:
            pass
            
        return None

    # This is a fallback method that doesn't rely on Selenium for Streamlit Cloud
    def extract_url_without_selenium(url):
        """
        A simpler method to extract the real URL by using just requests and BeautifulSoup.
        Not as powerful as Selenium but works in restricted environments.
        """
        try:
            # First try the mobile site approach which doesn't need Selenium
            extracted_url = extrair_via_api_mobile(url)
            if extracted_url:
                return extracted_url
                
            # If mobile approach fails, try a direct request
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
            
            # Check if we were redirected to a more useful URL
            if response.url != url and '/videos/' in response.url:
                return response.url
                
            # Parse with BeautifulSoup
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Look for og:url meta tag
            og_url = soup.find('meta', property='og:url')
            if og_url and og_url.get('content'):
                return og_url['content']
                
            # Look for video meta tags
            og_video = soup.find('meta', property='og:video:url')
            if og_video and og_video.get('content'):
                return og_video['content']
                
            # Look for canonical link
            canonical = soup.find('link', rel='canonical')
            if canonical and canonical.get('href'):
                return canonical['href']
                
            # If all else fails, extract any facebook.com links that might be useful
            all_links = soup.find_all('a')
            for link in all_links:
                href = link.get('href')
                if href and 'facebook.com' in href and any(x in href for x in ['/videos/', '/watch/', '/photo/']):
                    # Make absolute if relative URL
                    if not href.startswith('http'):
                        href = 'https://www.facebook.com' + href
                    return href
                    
        except Exception as e:
            pass
            
        return None

    # Modified version of limpar_url_facebook that handles Streamlit Cloud limitations
    def limpar_url_facebook(url):
        """
        Tenta obter a URL real de um an√∫ncio do Facebook.
        Retorna apenas a URL base sem par√¢metros de consulta (sem o que vem ap√≥s o '?').
        Modified to work on Streamlit Cloud.
        """
        if not url or 'facebook.com' not in url:
            return url, "erro", "URL inv√°lida"
        
        # Inicializar vari√°veis
        real_url = None
        status = "sucesso"
        mensagem = ""
        
        # Verificar se a URL j√° est√° limpa (n√£o cont√©m par√¢metros de an√∫ncio)
        if '/videos/' in url and '?' in url:
            # Se j√° √© uma URL de v√≠deo, apenas remover os par√¢metros
            base_url = url.split('?')[0]
            return base_url, "sucesso", "URL de v√≠deo encontrada"
        
        # Verificar se temos um mapeamento manual para esta URL
        if 'manual_mappings' in st.session_state and url in st.session_state.manual_mappings:
            mapped_url = st.session_state.manual_mappings[url]
            # Remover par√¢metros ap√≥s '?'
            if '?' in mapped_url:
                mapped_url = mapped_url.split('?')[0]
            return mapped_url, "sucesso", "URL encontrada no mapeamento"
        
        # Determine if we can use Selenium in this environment
        selenium_works = check_selenium_available()
        
        try:
            if selenium_works and SELENIUM_AVAILABLE:
                # Try the Selenium approach first if available
                real_url = extrair_url_real_via_browser(url)
            
            # If Selenium failed or isn't available, try alternative methods
            if not real_url:
                real_url = extract_url_without_selenium(url)
            
            if real_url:
                # Ensure real_url is a string (not bytes)
                if isinstance(real_url, bytes):
                    real_url = real_url.decode('utf-8')
                    
                # Remover tudo ap√≥s o '?' na URL
                if '?' in real_url:
                    clean_url = real_url.split('?')[0]
                else:
                    clean_url = real_url
                
                # Remover tudo ap√≥s o '#' se existir
                if '#' in clean_url:
                    clean_url = clean_url.split('#')[0]
                
                return clean_url, "sucesso", "URL extra√≠da com sucesso"
            else:
                return url, "aviso", "N√£o foi poss√≠vel extrair a URL"
        except Exception as e:
            return str(url), "erro", f"Erro durante processamento: {str(e)}"

    # Fun√ß√£o simplificada para exibir resultados da URL
    def display_url_results(original_url, cleaned_url_tuple):
        """Exibe apenas o antes e depois da URL"""
        url_limpa, status, mensagem = cleaned_url_tuple
        
        # Ensure url_limpa is a string
        if isinstance(url_limpa, bytes):
            url_limpa = url_limpa.decode('utf-8')
        
        st.markdown("### URL Original:")
        st.code(original_url)
        
        st.markdown("### URL Limpa:")
        st.code(url_limpa)
        
        return url_limpa

    def processar_lote_urls(texto_urls):
        """Processa um lote de URLs, uma por linha e retorna resultados com status."""
        urls = [linha.strip() for linha in texto_urls.split('\n') if linha.strip()]
        resultados = []
        
        for url in urls:
            # A fun√ß√£o agora retorna uma tupla (url_limpa, status, mensagem)
            url_limpa, status, mensagem = limpar_url_facebook(url)
            resultados.append((url, url_limpa, status, mensagem))
        
        return resultados

    # Interface principal
    tabs = st.tabs(["URL √önica", "Lote de URLs"])

    # Tab para URL √∫nica
    with tabs[0]:
        url_input = st.text_input("Cole a URL do an√∫ncio do Facebook", 
                                  placeholder="https://www.facebook.com/...",
                                  help="URL original do an√∫ncio com par√¢metros de rastreamento")
        
        clean_button = st.button("üîç Limpar URL", key="btn_limpar_unica", use_container_width=True)
        
        if '√∫ltimo_processo' not in st.session_state:
            st.session_state.√∫ltimo_processo = {}
            
        if clean_button:
            if url_input:
                with st.spinner("‚è≥ Processando a URL..."):
                    # Processar a URL
                    cleaned_url_tuple = limpar_url_facebook(url_input)
                    
                # Exibir informa√ß√µes simplificadas
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### URL Original:")
                    st.code(url_input, language="text")
                
                with col2:
                    url_limpa = cleaned_url_tuple[0]
                    st.markdown("### URL Limpa:")
                    st.code(url_limpa, language="text")
                
                # Bot√£o para enviar para compra
                if st.button("‚Ü™Ô∏è Enviar URL para a se√ß√£o de compra", key="enviar_para_compra"):
                    # Transferir a URL para o lado de compra
                    st.session_state.url_para_comprar = url_limpa
                    st.rerun() # Importante: for√ßar recarregamento da p√°gina
                
                # Resultado final
                st.markdown(
                    f"""
                    <div class="resultado">
                        <h4>Resultado Final:</h4>
                        <p>{url_limpa}</p>
                    </div>
                    """, 
                    unsafe_allow_html=True
                )
            else:
                st.error("‚ùå Por favor, insira uma URL para limpar.")
    
    # Tab para lote de URLs
    with tabs[1]:
        lote_urls = st.text_area(
            "Cole v√°rias URLs (uma por linha)", 
            height=150,
            placeholder="https://www.facebook.com/...\nhttps://www.facebook.com/..."
        )
        
        process_button = st.button("üîÑ Processar Lote", key="btn_limpar_lote", use_container_width=True)
            
        if process_button:
            if lote_urls:
                urls = [linha.strip() for linha in lote_urls.split('\n') if linha.strip()]
                
                if not urls:
                    st.error("‚ùå Nenhuma URL v√°lida encontrada no texto.")
                else:
                    resultados = []
                    
                    # Barra de progresso
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, url in enumerate(urls):
                        # Atualizar progresso
                        progress = (i) / len(urls)
                        progress_bar.progress(progress)
                        status_text.text(f"Processando URL {i+1} de {len(urls)}...")
                        
                        # Processar URL
                        cleaned_url_tuple = limpar_url_facebook(url)
                        resultados.append((url, cleaned_url_tuple))
                    
                    # Completar o progresso
                    progress_bar.progress(1.0)
                    status_text.text(f"‚úÖ Processamento conclu√≠do! {len(urls)} URLs processadas.")
                    
                    # Exibir resultados simplificados
                    st.markdown("### URLs Processadas:")
                    for i, (original, clean_tuple) in enumerate(resultados, 1):
                        url_limpa = clean_tuple[0]
                        # Ensure url_limpa is a string
                        if isinstance(url_limpa, bytes):
                            url_limpa = url_limpa.decode('utf-8')
                        
                        st.markdown(f"**URL {i}**")
                        st.code(f"Original: {original}\nLimpa: {url_limpa}")
                    
                    # Preparar URLs limpas
                    urls_limpas = [
                        clean_tuple[0] if isinstance(clean_tuple[0], str)
                        else clean_tuple[0].decode('utf-8') if isinstance(clean_tuple[0], bytes)
                        else str(clean_tuple[0])
                        for _, clean_tuple in resultados
                    ]
                    
                    # Mostrar um resumo das URLs limpas
                    st.markdown("### Todas as URLs Limpas:")
                    todas_limpas = "\n".join(urls_limpas)
                    st.code(todas_limpas)
                    
                    # Bot√£o para baixar as URLs limpas
                    st.download_button(
                        label="üì• Baixar URLs Limpas",
                        data=todas_limpas,
                        file_name="urls_limpas.txt",
                        mime="text/plain"
                    )
                    
                    # Bot√£o para enviar para compra
                    if st.button("‚Ü™Ô∏è Enviar URLs para a se√ß√£o de compra", key="enviar_lote_para_compra"):
                        # Transferir as URLs para o lado de compra
                        st.session_state.urls_para_comprar_lote = urls_limpas
                        st.rerun() # Importante: for√ßar recarregamento da p√°gina
            else:
                st.error("‚ùå Por favor, insira pelo menos uma URL para processar.")

# ---------------------------------------------------------------------------- #
#                 PARTE 2: COMPRAR ENGAJAMENTO
# ---------------------------------------------------------------------------- #

with col_comprar:
    st.markdown("<div class='column-title'><h3>üõí Comprar Engajamento</h3></div>", unsafe_allow_html=True)
    
    # --- Configura√ß√µes da API ---
    API_KEY = "k*4)r(4*C*5@t)3Ty(w*5r)Y)Z("  # Chave de API fornecida
    API_URL = "https://www.smmraja.com/api/v3"
    
    # --- Exibir saldo em formato simples e confi√°vel ---
    st.markdown("### üí∞ Saldo Dispon√≠vel")
    
    # Bot√£o para consultar/atualizar saldo
    if st.button("üîÑ Consultar Saldo", key="consultar_saldo"):
        with st.spinner("Consultando saldo..."):
            try:
                # Realizar consulta de saldo
                payload = {
                    "key": API_KEY,
                    "action": "balance"
                }
                
                response = requests.post(API_URL, data=payload)
                st.write("Resposta da API:", response.text)  # Debug
                
                data = response.json()
                
                if "error" in data:
                    st.error(f"Erro retornado pela API: {data['error']}")
                else:
                    saldo = data.get("saldo", "N/A")
                    moeda = data.get("moeda", "")
                    
                    # Exibir o saldo em um formato simples e confi√°vel
                    st.success(f"Saldo atual: {saldo} {moeda}")
                    
                    # Armazenar na sess√£o para uso futuro
                    st.session_state.saldo_info = (saldo, moeda)
            except Exception as e:
                st.error(f"Erro ao consultar saldo: {str(e)}")
    
    # Mostrar saldo armazenado (se dispon√≠vel)
    elif "saldo_info" in st.session_state:
        saldo, moeda = st.session_state.saldo_info
        st.info(f"√öltimo saldo consultado: {saldo} {moeda}")
    else:
        st.info("Clique no bot√£o para consultar seu saldo atual")
    
    st.markdown("### Configurar Pedidos de Engajamento")
    
    # --- Carrega os engajamentos cadastrados ---
    engajamentos = get_engajamentos()
    if engajamentos:
        # Filtra os engajamentos por tipo
        opcoes_like = {f"{row[1]} (ID: {row[2]})": row[2] for row in engajamentos if row[3] == "Sim" and row[4].lower() == "like"}
        opcoes_uau = {f"{row[1]} (ID: {row[2]})": row[2] for row in engajamentos if row[3] == "Sim" and row[4].lower() == "uau"}
        opcoes_amei = {f"{row[1]} (ID: {row[2]})": row[2] for row in engajamentos if row[3] == "Sim" and row[4].lower() == "amei"}
    else:
        opcoes_like = {}
        opcoes_uau = {}
        opcoes_amei = {}

    # --- Se√ß√£o para Like (opcional) ---
    col1, col2, col3 = st.columns(3)
    with col1:
        ativar_like = st.checkbox("Ativar üëç Like")
        if ativar_like:
            if opcoes_like:
                like_engagement = st.selectbox("Selecione o engajamento para Like", options=list(opcoes_like.keys()))
                like_service = opcoes_like[like_engagement]
                like_quantity = st.number_input("Quantidade para Like", min_value=1, value=100, step=1)
            else:
                st.warning("N√£o h√° engajamentos do tipo Like cadastrados.")
                like_service = None
        else:
            like_service = None

    # --- Se√ß√£o para Uau (opcional) ---
    with col2:
        ativar_uau = st.checkbox("Ativar üòÆ Uau")
        if ativar_uau:
            if opcoes_uau:
                uau_engagement = st.selectbox("Selecione o engajamento para Uau", options=list(opcoes_uau.keys()))
                uau_service = opcoes_uau[uau_engagement]
                uau_quantity = st.number_input("Quantidade para Uau", min_value=1, value=200, step=1)
            else:
                st.warning("N√£o h√° engajamentos do tipo Uau cadastrados.")
                uau_service = None
        else:
            uau_service = None

    # --- Se√ß√£o para Amei (opcional) ---
    with col3:
        ativar_amei = st.checkbox("Ativar üòç Amei")
        if ativar_amei:
            if opcoes_amei:
                amei_engagement = st.selectbox("Selecione o engajamento para Amei", options=list(opcoes_amei.keys()))
                amei_service = opcoes_amei[amei_engagement]
                amei_quantity = st.number_input("Quantidade para Amei", min_value=1, value=400, step=1)
            else:
                st.warning("N√£o h√° engajamentos do tipo Amei cadastrados.")
                amei_service = None
        else:
            amei_service = None

    # --- Campo para adicionar links ---
    st.markdown("### Links")
    
    # Verificar se recebemos URLs da se√ß√£o de limpeza
    if "url_para_comprar" in st.session_state and st.session_state.url_para_comprar:
        # Auto-preencher o campo de texto com a URL recebida
        links_input = st.text_area(
            "Adicione os links (um por linha)", 
            value=st.session_state.url_para_comprar,  # Pre-preencher com a URL limpa
            placeholder="https://exemplo.com/link1"
        )
        
        # Bot√£o para limpar a URL recebida
        if st.button("‚ùå Limpar URL recebida", key="limpar_url_recebida"):
            st.session_state.url_para_comprar = None
            st.rerun()
    elif "urls_para_comprar_lote" in st.session_state and st.session_state.urls_para_comprar_lote:
        # Auto-preencher com o lote de URLs recebidas
        links_input = st.text_area(
            "Adicione os links (um por linha)",
            value="\n".join(st.session_state.urls_para_comprar_lote),
            placeholder="https://exemplo.com/link1"
        )
        
        # Bot√£o para limpar as URLs recebidas
        if st.button("‚ùå Limpar URLs recebidas", key="limpar_urls_recebidas"):
            st.session_state.urls_para_comprar_lote = []
            st.rerun()
    else:
        links_input = st.text_area("Adicione os links (um por linha)", placeholder="https://exemplo.com/link1")

    # --- Fun√ß√£o para enviar os pedidos ---
    def enviar_pedidos(api_key, api_url, reaction_data, links_str):
        """
        reaction_data: dicion√°rio com cada rea√ß√£o e sua respectiva tupla (service_id, quantidade),
                       ex: {"Like": (service_id_like, 100), "Uau": (service_id_uau, 200)}
        """
        links = [link.strip() for link in links_str.splitlines() if link.strip()]
        if not links:
            return "Erro: Nenhum link foi inserido."
        
        resultados = []
        
        # Para cada rea√ß√£o ativada, envia um pedido para cada link
        for reaction, (service_id, quantidade) in reaction_data.items():
            for link in links:
                payload = {
                    "key": api_key,
                    "action": "add",
                    "service": service_id,
                    "link": link,
                    "quantity": quantidade
                }
                try:
                    response = requests.post(api_url, data=payload)
                    response_data = response.json()
                    resultados.append(
                        f"**{reaction}** - **Engajamento ID:** {service_id} | **Link:** {link}\n"
                        f"**Resposta:** {json.dumps(response_data, indent=2)}"
                    )
                except json.JSONDecodeError:
                    resultados.append(
                        f"**{reaction}** - **Engajamento ID:** {service_id} | **Link:** {link}\n"
                        f"**Erro:** Resposta inv√°lida: {response.text}"
                    )
                except Exception as e:
                    resultados.append(
                        f"**{reaction}** - **Engajamento ID:** {service_id} | **Link:** {link}\n"
                        f"**Erro:** {str(e)}"
                    )
        
        return "\n\n".join(resultados)

    if st.button("üì§ Enviar Pedidos"):
        # Monta o dicion√°rio apenas com as rea√ß√µes que foram ativadas
        reaction_data = {}
        if ativar_like:
            if like_service:
                reaction_data["Like"] = (like_service, like_quantity)
            else:
                st.error("Selecione um engajamento para Like.")
        if ativar_uau:
            if uau_service:
                reaction_data["Uau"] = (uau_service, uau_quantity)
            else:
                st.error("Selecione um engajamento para Uau.")
        if ativar_amei:
            if amei_service:
                reaction_data["Amei"] = (amei_service, amei_quantity)
            else:
                st.error("Selecione um engajamento para Amei.")
        
        if not reaction_data:
            st.error("Por favor, ative pelo menos uma rea√ß√£o para enviar pedidos.")
        else:
            resultado = enviar_pedidos(API_KEY, API_URL, reaction_data, links_input)
            st.markdown("### üìà Resultados")
            st.text_area("", resultado, height=300)